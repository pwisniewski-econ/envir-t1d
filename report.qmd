---
execute:
  echo: false
  message: false
  warning: false
format:
    pdf: 
        number-sections: true
        block-headings: false
        fig-format: pdf
        code-block-border-left: "#5b5b5b"
        code-block-bg: "#fafafa "
        highlight-style: pygments
        documentclass: article
        toc: true
        toc-depth: 2
        toccolor: black
        citecolor: black
        urlcolor: gray
        fontsize: "12pt"
        pdf-engine: pdflatex
        include-before-body: 
        - text: |
            \input{ressources/title-page/title-page.tex}
        include-in-header:
        - text: |
            \usepackage{graphicx}
            \usepackage{pdflscape}
            \usepackage{pdfpages}
            \newcommand*{\boldone}{\text{\usefont{U}{bbold}{m}{n}1}}
            \usepackage[a4paper, portrait, footnotesep=0.75cm, margin=2.54cm]{geometry}
            \usepackage{enumitem}
            \usepackage{parskip}
            \usepackage{titling}
            \linespread{1.5}
            \usepackage[T1]{fontenc}
            \usepackage[hidelinks]{hyperref}
            \hypersetup{linkcolor={black}}
            \usepackage{amsmath}
            \usepackage{amsfonts}
            \usepackage[normalem]{ulem}
            \usepackage{times}
            \usepackage{sectsty}
            \usepackage[backend=biber, url=false, style=authoryear, sorting=ydnt]{biblatex}
---



```{python}
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
```

\clearpage

# General Introduction

Type 1 diabetes (T1D) is an autoimmune disease in which the body’s immune system attacks and destroys the insulin-producing beta cells in the pancreas. Without treatment, or in cases of poor disease management, T1D can lead to serious complications such as diabetic ketoacidosis and hypoglycemia. In France, around 4,000 new cases are diagnosed each year, and between 2018 and 2022, approximately 180,000 people were living with T1D. This rising incidence—estimated at an average annual rate of 2\% to 5\% in pediatric populations—suggests that T1D is a growing public health concern.

The origin of T1D is complex, involving a combination of genetic predisposition and environmental triggers. Numerous environmental and socio-demographic factors have been associated with the development of the disease, although their impact may vary across regions and populations. In France, for instance, the prevalence of T1D is not evenly distributed across regions. [insert regional numbers in 2023] These regional disparities suggest that external factors—such as lifestyle, access to healthcare, socioeconomic conditions, and potential environmental exposures like pollution and climate—may influence disease risk. Identifying at-risk individuals early and gaining a clearer understanding of the specific environmental contributors to T1D remain key public health challenges. 

Our study focuses on inference rather than prediction. Our goal is to better understand the relationship between environmental, social and economic factors and the incidence of T1D. We aim to assess how various exposures—such as air pollution, access to healthcare services, or socio-demographic variables—may influence the likelihood of developing T1D in different districts. [to develop]

To conduct our analysis, we combine individual-level hospital data from the French PMSI (Information systems medicalization program) with a wide range of open-access external datasets. We received additional data from Sanofi, including environmental variables such as air pollution and gas emissions, as well as socio-economic indicators at the district level. To capture the local environment more precisely, we integrated SIRENE data, which provides information on both commercial (e.g., food stores, fitness centers) and public infrastructure. We further enrich our dataset with meteorological data from Météo France. 



\newpage 

# Literature Review

For our project, it is crucial to understand what the existing literature says about environmental and social risk factors for Type 1 diabetes. Reviewing this literature help us identify the most studied factors and the remaining research gaps. This section summarizes key findings across several factors, from air pollution and nutrition to stress and socioeconomic conditions.

## Air pollution

Air pollution is among the most studied environmental factors in recent years regarding the risk of T1D onset, especially in children. ozone (O3), nitrogen oxide (NOx) and particulate matter (PM10 and PM2.5) are known for their effects on inflammation, oxidative stress and immune regulation. Numerous studies support that exposure to these air pollutants during pregnancy or early life could contribute to higher risk of developing T1D. 
A Canadian study carried out by Elten et al. (2020) examined around 750k children and found that maternal exposure to ozone during first trimester of pregnancy is associated to increased risk of early-onset pediatric diabetes. A study in Israel by Taha-Khalde et al (2021) supported this result by showing that children whose mothers were exposed to high concentration of O3 (third and fourth quartiles) during pregnancy had higher chances of developing T1D. However, Taha-Khalde also investigated the role of PM10 and PM2.5 exposure but found no clear associations after adjusting for socioeconomic status and meteorological conditions. A study carried out in California by Hathout et al. (2006) also found that children with T1D had higher cumulative exposure to O3 from birth, which reinforces the potential association between long-term ozone exposure and autoimmune diabetes.
Finally, in Poland, Michalska et al. (2020) explored regional variation in air pollution and T1D incidence. They found a significant positive correlation between annual average PM10 levels and incidence of T1D among children aged between 0 and 18. However, they found no significant correlation between NO2 levels and incidence of T1D in this population. The literature seems to suggest that NO2 plays a secondary role compared to oxidative pollutants like ozone and fine particulate matter. 

## Vitamin D and sun exposure

Another widely researched factor is vitamin D, it is seen as a protective factor because of its role in the immune system and pancreatic function. The active form of vitamin D (1,25(OH)2D3) attaches to receptors (VDR) present immune cells and beta cells, where it helps regulate immune responses by limiting inflammation and promoting immune tolerance, which could reduce the likelihood of the immune system attacking the beta-cells, as in T1D. Also, vitamin D contributes to calcium balance, essential for proper insulin secretion. 
Many observational studies suggest that vitamin D supplementation during childhood might lower the risk on developing T1D. A large Finnish birth cohort study by Hyppönen et al. (2001) found that supplementation of vitamin D during childhood was associated with an 88% lower risk of developing T1D compared to children who didn’t receive vitamin D. The EURODIAB case control-study confirmed this result, showing vitamin D supplementation in infancy was associated with 33% lower odds of developing T1D later in life. A meta-analysis – conducted by Zipitis and Akobeng (2008) – using five studies supported those findings, showing that children with supplementation of vitamin D had 29% lower risk of developing T1D compared to other children. 
Vitamin D is primarily produced in the skin through exposure to ultraviolet B (UVB) rays from sunlight, making sun exposure an essential component for maintaining high level of vitamin D. Geographic differences in UVB quantities – determined by latitude and cloud coverage – can therefore influence vitamin D status in population. A studied by Mohr et al. (2008) carried out during several years among children aged 0-14 in 51 regions worldwide found that higher regional USB irradiance was strongly associated with lower incidence rates of T1D in children. The study observed a clear variation with latitude: regions closer to the equator, with greater UVB exposure, had significantly lower T1D incidence compared to regions farther from the equator.
Despite consistent results across numerous studies, these results don’t establish a causal relationship between supplementation of vitamin D during childhood and development of T1D. Most studies are observational and rely on retrospective data, often based on parental recall of supplementation, without objective measurements of vitamin D levels. There are still many questions about ideal dose, timing and duration and heterogeneity effects. 

## Dietary factors

Dietary factors are known to have an impact on the onset of Type 2 diabetes, but they have also been examined in relation to T1D, especially through its impact on immune development and pancreatic beta-cell stress. Several dietary factors during pregnancy, infancy or childhood could contribute to either increasing or reducing risk of developing Type 1 diabetes.  Early exposure to certain foods, such as cow’s milk or processed meats, has been associated with a higher risk, possibly due to the presence of inflammatory compounds like nitrites and advanced glycation end-products that may promote beta-cell damage​ (Virtanen 2016). 
Many prospective and case-control studies have investigated the effects of diet on the onset of T1D. Early introduction of cow’s milk and short breastfeeding duration have both been associated with an increased risk of islet autoimmunity and T1D, particularly when they occur in the first months of life​ (Virtanen 2016). In a Swedish cohort-study, short breastfeeding and early cow’s milk exposure were associated with higher risk of autoantibody development. Furthermore, early introduction of solid foods has also been linked to a higher risk of islet autoimmunity in genetically susceptible children. A randomized trial found that giving infants a hydrolyzed formula instead of a standard cow’s milk–based formula in the first 6-8 months of life could delay the emergence of islet cell autoimmunity. 
According to studies, diet continues to play a role in older children. A Swedish study found that children developing T1D had significantly higher intakes of energy, carbohydrates, and especially sugars compared to other children​. High sugar consumption remained a significant risk factor after adjusting for total energy intake, suggesting a specific impact beyond general overnutrition. Moreover, Traversi et al (2020) conducted a small study on children of Italian origin and migrant families in Italy, which included 40 cases and 56 controls. They observed a modest but significant association between higher total caloric intake and the likelihood of developing T1D. In particular, high intake of protein, fat, or carbohydrates individually was also associated with a slightly increased risk of the disease. 
Evidence suggests that family dietary habits - especially those influencing early nutrition and energy intake - could play a role in shaping T1D risk. However, a clear causal relationship between diet and T1D has not been established. Most studies are observational and may be influenced by bias or confounding factors.

## Psychological stress

In addition to physical exposures, psychological stress has been proposed as a possible trigger for T1D, particularly when stress occurs during sensitive developmental periods. Two studies have studied this relation in the context of acute, traumatic life events. Zung et al. (2012) reported a significant increase in T1D incidence among Israeli children following the Second Lebanon War, suggesting that important levels of psychological stress may act as a trigger​. Virk et al. (2010) found that children whose mothers experienced the death of a close family member during pregnancy - particularly in cases of sudden or traumatic loss, such as the death of a partner or a child - were at greater risk of developing T1D, with the association being especially strong among girls​. 
However, the idea that « post-traumatic » type 1 diabetes exists remain controversial. The literature is inconsistent, some studies report a clear link between traumatic life events and diabetes onset, and other studies, including studies conducted in high-prevalence countries like Sweden, find no such association. (Littorin et al. 2001) 
A key limitation of the literature on the relation between stress and type 1 diabetes is the narrow focus on extreme events such as wars or losses of loved ones. Few studies have focused on chronic and everyday stressors such as school pressure, neighborhood criminality or family instability and their influence on developing T1D. Furthermore, most studies don’t include physiological data (cortisol levels or immune markers), making it difficult how stress contribute to autoimmune processes. 

## Tobacco use and exposure

Tobacco use and exposure have also raised concerns regarding onset of T1D, due to their known effects on insulin secretion and pancreatic beta-cell function. While smoking is well known for its effects on insulin resistance, evidence also points to its role in impairing insulin secretion. A Japanese cohort study by Morimoto et al. (2013), which followed around 2k men over several years, found that current smokers were nearly twice as likely to develop impaired insulin secretion compared to men who never smoke. The risk increased in a dose-dependent manner with the number of pack-years smoked, suggesting a cumulative effect. Interestingly, smoking was not significantly associated with insulin resistance in this cohort, reinforcing the idea that smoking may directly damage beta cells rather than simply altering insulin sensitivity​. 
A Swedish study confirmed those results showing that smokers had significantly lower beta-cell function that people who had never smoked, indicating reduced insulin secretion capacity. Notably, this association was not observed in women, suggesting possible sex-specific biological responses to tobacco exposure​. The mechanism at stake here is that smoking is associated with increased oxidative stress and inflammation, both of which could contribute to beta-cell apoptosis or dysfunction. 
While these studies show that smoking can impair beta-cell function, they do not clearly link smoking to the development of T1D itself. Most research focuses on adults and does not address early-life exposure, when T1D typically begins.

## Socioeconomic factors

Lastly, socioeconomic factors are increasingly studied as potential non-genetic contributors to T1D. Several studies suggest socioeconomic factors can influence access to healthcare and exposure to environmental factors and behavioral risk factors, which may affect onset of T1D. The study by Traversi et al. (2020) showed that children receiving regular health check-ups were significantly less likely to develop the disease (odds ratio of 0.37). This finding shows the importance of access to healthcare and early monitoring. 
Further analyses support the idea that regional deprivation is associated with higher T1D incidence. A large study by Buchmann et al. (2023), using registry data from nearly 25,000 children in Germany, found that districts with very high socioeconomic deprivation (as measured by the German Index of Socioeconomic Deprivation, GISD) had a higher incidence of T1D compared to those with very low deprivation. Another study carried in Germany by Prel et al. (2007) showed that higher deprivation scores – based on income, education and professional training – were significantly associated with increased T1D incidence across regions. The study also reported a clear linear trend, with incidence rising as deprivation increased. 
It is common to use income of the household, education of parents to measure socioeconomic status. However, they may act as proxies for more complex underlying mechanisms. These includes differences in health behaviors, nutrition quality, stress exposure, and healthcare access, which may not be fully captured by standard indicators. Low parental education could be associated with reduced health literacy, leading to delayed recognition of early T1D symptoms or poor diabetes management. Income may reflect a family's ability to access healthy food, stable housing and preventive care, which are factors that could affect the likelihood of developing T1D. 
Despite the associations found in these studies, there is no definitive evidence that low socioeconomic status directly causes T1D. Most available studies are observational and cannot account for individual-level confounding or causal mechanisms. Moreover, results are not always consistent across countries and time periods, possibly due to differences in healthcare systems, social safety nets, and population genetics.




\newpage

# Data Presentation


```{python}
df_arr_full = pd.read_feather("results_building/arrondissement-full.feather")
df_dep_full = pd.read_feather("results_building/dep-full.feather")

def make_pca(
    df: pd.DataFrame,
    col_for_PCA: list = None,
    col_to_remove: list = None,
    n_components: int = 10
    ):

  """
  Effectue une PCA sur un dataframe
  Si col_for_PCA est renseigné, la PCA est effectué sur ces colonnes,
  Si col_to_remove est renseigné, ces colonnes sont supprimées du dataframe et la
  PCA est faite sur le DataFrame

  Renvoie:
  - df_pca: DataFrame contenant les composantes principales
  - variance_expliquee: Variance expliquée par chaque composante
  - loadings_df: DataFrame contenant les loadings
  """

  scaler = StandardScaler()
  imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
  pca = PCA(n_components=10)

  if col_to_remove is not None:
    df = df.drop(col_to_remove, axis=1)

  elif col_for_PCA is not None:
    df = df[col_for_PCA]

  # On scale les variables de notre dataframe
  df_scaled = scaler.fit_transform(df)

  # On applique la stratégie pour les valeurs manquantes
  df_imputed = pd.DataFrame(imputer.fit_transform(df_scaled))

  # On réalise la PCA
  pca_result = pca.fit_transform(df_imputed)

  # On stocke la PCA dans un dataframe
  df_pca = pd.DataFrame(pca_result,
                      columns=[f'PC{i+1}' for i in range(pca_result.shape[1])],
                      index=df.index
                      )
  df_pca.index = df_pca.index.astype(str)

  variance_expliquee = pca.explained_variance_ratio_
  loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
  loadings_df = pd.DataFrame(loadings, columns=[f'PC{i+1}' for i in range(loadings.shape[1])], index=df.columns)

  return df_pca, variance_expliquee, loadings_df


def plot_variance_cumule(
    pca : pd.DataFrame,
    var_exp : np.ndarray,
    figsize : tuple = (6,4),
    marker : str = 'o',
    linestyle : str = '--',
    xlabel : str = 'Nombre de composantes',
    ylabel : str = 'Variance expliquée cumulée',
    grid : bool = True
  ):

  plt.figure(figsize=figsize)
  plt.plot(range(1, pca.shape[1]+1), np.cumsum(var_exp), marker=marker, linestyle=linestyle)
  plt.xlabel(xlabel)
  plt.ylabel(ylabel)
  plt.grid(grid)
  plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)
  plt.show()
  


def plot_small_grid(
    loadings : pd.DataFrame,
    col_to_print: list,
    cols : int = 3,
    set_lim : bool = False,
    lim : tuple = None,
    colors : list = None
):

  n = len(loadings)

  # Définir la taille de la grille automatiquement
  rows = (n + cols - 1) // cols  # Calcul du nombre de lignes nécessaires


  fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))
  axes = axes.flatten()  # Pour itérer facilement, même si 1 seule ligne

  if colors is None:
    cmap = plt.get_cmap("tab20")
    colors = [cmap(i) for i in range(len(col_to_print))]

  for i, (idx, row) in enumerate(loadings[col_to_print].iterrows()):
      axes[i].bar(row.index, row.values, color=colors)
      axes[i].set_title(f"{idx}")

      if set_lim:
        if lim is None:
          axes[i].set_ylim(loadings[col_to_print].values.min(), loadings[col_to_print].values.max())
        else:
          axes[i].set_ylim(lim[0], lim[1])

  # Cacher les axes inutilisés s'il y en a
  for j in range(i+1, len(axes)):
      axes[j].axis('off')

  plt.tight_layout()
  plt.show()

col_for_PCA = [
  'dip_001T',
  'dip_200R',
  'dip_300R',
  'dip_350R',
  'dip_500R',
  'dip_600R',
  'dip_700R',
  'proportion_imposable_ens_arr',
  'd1_ens_arr',
  'q1_ens_arr',
  'q2_ens_arr',
  'q3_ens_arr',
  'd9_ens_arr',
  'gini_ens_arr',
  ]

df_arr_full.index= df_arr_full['arr24']

pca_arr_ses, var_exp_arr_ses, load_arr_ses = make_pca(
    df = df_arr_full,
    col_for_PCA = col_for_PCA,
    n_components = 10
    )
```

```{python}
#| fig-align: 'center'
#| fig-cap: "Share of Explained Variance, Socio-Economic Variables, PCA"
plot_variance_cumule(
    pca = pca_arr_ses,
    var_exp = var_exp_arr_ses,
)
```

```{python}
plot_small_grid(
    loadings = load_arr_ses,
    col_to_print = ['PC1','PC2','PC3','PC4','PC5','PC6'],
    cols = 4,
    set_lim = True,
    lim = (-1, 1),
)


```


\newpage 

# Methodological Overview

Selecting variables for the primary model presented a significant challenge due to the numerous features available in the rich dataset created during this project. While automatic variable selection techniques, such as the elastic net, were considered, they are ill-suited to this research's primary goal: inference rather than prediction (as established in the introduction).

Employing variable selection methods driven by relationships within the dataset itself compromises subsequent statistical inference. Most notably, it renders p-values unreliable for controlling the risk of Type I errors. Furthermore, automatic selection introduces interpretative difficulties. In observational settings often characterized by unobserved heterogeneity, it becomes challenging to discern the substantive reasons for a variable's inclusion beyond its predictive performance or simple correlation with the outcome (here, T1D).

Therefore, we adopted a manual selection approach. This allows us to incorporate variables based on pre-defined hypotheses regarding their potential influence, informed by theoretical considerations from the literature, results from our exploratory PCA (which excluded T1D-related variables), and descriptive statistics concerning seasonality and associated diagnoses. For transparency, the justification for each chosen variable is provided in the annex to this report.

Our primary analysis employs Poisson and Negative Binomial regression models to explain the number of "new cases" observed at various geographical levels. To address inherent concerns about the ecological fallacy, where aggregate-level associations may not accurately reflect individual-level risks, we leverage data across different geographic levels and conduct heterogeneity analyses within selected sub-populations. Finding consistent results across these different levels and groups strengthens the evidence for the robustness of inference.

However, given the limitations common to observational studies, our initial findings are still sensitive to the specific set of control variables included in the model. Therefore, we identify promising explanatory variables from these primary models to investigate further using methods designed for more robust causal inference, treating these variables conceptually as "treatments." \newpage 

Specifically, we conduct subsequent analyses using either:

1.	**Panel data models with fixed effects**: This approach utilizes longitudinal data to control for time-invariant unobserved characteristics of the geographical units.
2.	**Double/Debiased Machine Learning (DDML)**: This technique uses machine learning to flexibly control for a potentially large number of confounding variables, aiming to provide less biased estimates of the "treatment" effect. While mechanically different, DDML shares a fundamental goal with methods like propensity score matching: estimating treatment effects by creating comparable conditions between units exposed and unexposed to the "treatment." Furthermore, DDML inherently aids in managing high-dimensional controls through a predictive first-stage estimation.

```{python}
MAIN_RESULTS = pd.read_csv('results_analysis/main_results.csv')

rename_map = {
    '(Intercept)': 'Intercept',
    'PC1': 'Socio-economic PC1',
    'PC2': 'Socio-economic PC2',
    'PC3': 'Socio-economic PC3',
    'ac_prop': 'Share of Homes with AC',
    'coups': 'Assaults (per 1k)',
    'diag_calcium': 'Share w/ Calcium Def.',
    'diag_family': 'Share w/ Family Issues',
    'diag_other_minerals': 'Share w/ Mineral Def.',
    'diag_tabacco': 'Share w/ Tabacco Addic.',
    'diag_vitamin_b12': 'Share w/ Vitamin B12 Def.',
    'diag_vitamin_b9': 'Share w/ Vitamin B9 Def.',
    'diag_vitamin_d': 'Share w/ Vitamin D Def.',
    'ges_resid': 'Residential GHG (per 1k)',
    'n_ape4722z': 'Butchers (per 1k)',
    'n_ape4723z': 'Fishmongers (per 1k)',
    'n_ape5610c': 'Fast Foods (per 1k)',
    'n_ape9312z': 'Gyms (per 1k)',
    'n_equip_a1': 'Public Services (per 1k)',
    'n_equip_c1': 'Teaching Primary (per 1k)',
    'n_equip_c2': 'Teaching Secondary (per 1k)',
    'n_equip_d2': 'Medical Facilities (per 1k)',
    'no2_mean_concentration': 'NO2 Concentration (air)',
    'o3_mean_concentration': 'O3 Concentration (air)',
    'pm10_mean_concentration': 'PM10 Concentration (air)',
    'prop_robinet': 'Share of tap drinkers',
    'prop_robinet:water_ph': 'Tap drinking x Water PH',
    'somo35_mean': 'Excess Ozone (air)',
    'tm_summer': 'Summer temperature',
    'tm_winter': 'Winter temperature',
    'water_no3': 'NO3 Concentrations (water)',
    'water_no3:prop_robinet': 'Tap drinking x NO3',
    'water_ph': 'Water PH',
    'aic': 'AIC',
    'df': 'DF',
    'dispersion': 'Dispersion',
    'pseudo_r2': 'Pseudo $R^2$'
}


default_pattern = r"^(\(|n_equip_|tm_|water_|prop_robinet|diag_vitamin_b|diag_other_minerals|diag_family|somo|ges)"

# Utility functions ----
def format_beta(beta: float, pval: float) -> str:
    rounded = round(beta, 5)
    stars = '***' if pval < 0.01 else '**' if pval < 0.05 else '*' if pval < 0.1 else ''
    return f"{rounded}{stars}"

def format_pval(pval: float) -> str:
    return str(round(pval, 4))

def escape_underscore(text: str) -> str:
    return text.replace('_', r'\_')

def build_table(
    df: pd.DataFrame,
    include_pval: bool = False,
    midrule_after: int = 15,
    exclude_pattern: str = None
) -> str:

    data = df.copy()

    # Format beta column
    data['beta'] = data.apply(lambda row: format_beta(row['beta'], row['pval']), axis=1)

    # Conditionally format or drop pval
    if include_pval:
        data['pval'] = data['pval'].apply(format_pval)
        metrics = ['beta', 'pval']
    else:
        data = data.drop(columns=['pval'])
        metrics = ['beta']

    # Prepare coefficient table
    coef = (
        data[['variable', 'description'] + metrics]
        .melt(
            id_vars=['variable', 'description'],
            var_name='metric',
            value_name='value'
        )
        .pivot_table(
            index=['variable', 'metric'],
            columns='description',
            values='value',
            aggfunc='first'
        )
        .reset_index()
    )

    # Optionally filter unwanted variables
    if exclude_pattern:
        coef = coef[~coef['variable'].str.match(exclude_pattern)]
    # Blank variable name for pval rows
    if 'metric' in coef:
        coef.loc[coef['metric'] != 'beta', 'variable'] = ''

    # Keep only relevant columns
    pattern = r'arr24|bv2022$'
    mask = coef.columns.str.contains(pattern, regex=True)
    cols_keep = ['variable'] + coef.columns[mask].tolist()
    coef = coef[cols_keep].fillna('-')

    # Model summary table
    model_stats = (
        df[df['description'].str.contains(pattern, regex=True)]
        [['dispersion', 'df', 'pseudo_r2', 'aic', 'description']]
        .drop_duplicates()
        .melt(id_vars='description', var_name='variable', value_name='value')
    )
    model_stats['value'] = model_stats['value'].round(3).astype(str)

    mask = model_stats['description'].str.startswith('negbinom') & (model_stats['variable'] == 'dispersion')
    model_stats.loc[mask, 'value'] = '-'

    
    model_table = model_stats.pivot(
        index='variable',
        columns='description',
        values='value'
    ).reset_index()

    # Combine tables
    full = pd.concat([coef, model_table], ignore_index=True, sort=False)

    # Rename variables for readability

    full['variable'] = full['variable'].map(rename_map).fillna(full['variable']).apply(lambda x: x if x else '')
    
    # Escape underscores (if any remain)
    full['variable'] = full['variable'].str.replace('_', r'\\_', regex=False)

    # Rename columns for LaTeX
    full.columns = [''] + [f"({i})" for i in range(1, full.shape[1])]

    # Export to LaTeX
    latex = full.to_latex(
        index=False,
        escape=False,
        na_rep='-',
        column_format='l' + 'c' * (full.shape[1] - 1),
        longtable=True
    )

    # Insert midrule
    lines = latex.splitlines()
    start = next(i for i, line in enumerate(lines) if line.strip().startswith(r"\midrule"))
    insert_pos = start + 1 + midrule_after
    lines.insert(insert_pos, r"\midrule")
    return '\n'.join(lines)



# Load data

```

# Results and Comments

As previously mentioned, we employ the widely used Poisson regression model to analyze the number of "incident" cases within specific French geographic units, the *bassins de vie 2022* and *arrondissements administratifs*. This model assumes that the case count $Y_i$ in unit $i$, conditional on a set of covariates $X_i$, follows a Poisson distribution: $Y_i | X_i \sim \mathcal{P}(\lambda_i)$. Model parameters are estimated using maximum likelihood estimation. The core of the model links the expected number of cases to covariates and population size through the conditional mean:
$$E[Y_i | \mathbf{X}_i, \text{pop}_i] = \lambda_i = \text{pop}_i\cdot\exp(\mathbf{X}_i^T \boldsymbol{\beta})$$
Here, $\text{pop}_i$ denotes the reference population under 30 years of age within the geographic unit $i$, serving as an offset that scales incidence risk to the relevant population size. The vector $\mathbf{X}_i$ includes both the control variables and variables of interest defined previously.

A key assumption of the Poisson model is the equality of its conditional mean and variance: $E[Y_i \mid \mathbf{X}_i] = \text{Var}(Y_i \mid \mathbf{X}_i) = \lambda_i$. However, our data exhibit evidence of a slight overdispersion (variance exceeding the mean), with calculated dispersion indices ranging from 1.2 to 1.5. To account for this, we also estimate a Negative Binomial (NB) regression model. The NB model typically retains the same structure for the conditional mean $\mu_i$ as the Poisson model but incorporates an additional dispersion parameter $\alpha$ to allow for greater variance:
$$ \mu_i = \text{pop}_i \cdot \exp(\mathbf{X}_i \boldsymbol{\beta}) \ \ \ \text{Var}(Y_i | \mathbf{X}_i) = \mu_i + \alpha \mu_i^2$$
This approach offers greater flexibility in modeling the variance compared to the standard Poisson model. While estimating the NB model can sometimes lead to instability, particularly with smaller sample sizes, it directly addresses the issue of overdispersion. For comparison, estimates from both the Poisson and NB models are presented in the following table, where (1) is the NB model at the arrondissement level, (2) is the NB model at the bv2022 level, (3) is a Poisson model at the arrondissement level and finally, (4) is a Poisson model at the bv2022 level.

```{python}
#| results: asis
#| output: asis
#| tbl-cap: "Main Regression Results"

print(build_table(
        MAIN_RESULTS[MAIN_RESULTS['description'].str.endswith(("arr24", "bv2022"))],
        include_pval=False,
        midrule_after=26,
        exclude_pattern=default_pattern
    ))
```

Full table in appendix

\newpage

```{python}
#| results: asis
#| output: asis
#| tbl-cap: "Subgroup Heterogeneity"

print(build_table(
        MAIN_RESULTS[MAIN_RESULTS['description'].str.endswith(("male", "female"))],
        include_pval=False,
        midrule_after=26,
        exclude_pattern=default_pattern
    ))
```

\newpage

```{python}
#| fig-cap: Poisson Fixed-Effects, Consumption Heterogeneity, Clustered SE
import pandas as pd
from plotnine import (
    ggplot, aes, geom_point, geom_errorbar, geom_vline,
    facet_wrap, theme_minimal, theme, element_text, labs,
    geom_errorbarh, theme_classic,theme_bw, scale_color_brewer,
    geom_abline
)
from matplotlib import font_manager
import matplotlib.pyplot as plt

# 1. Register your Times New Roman font
font_path = "ressources/fonts/Times-New-Roman.otf"
font_manager.fontManager.addfont(font_path)
# Use it everywhere in matplotlib/plotnine:
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['figure.dpi'] = 300

# 2. Read the CSV
df = pd.read_csv("results_analysis/poisson-fixed_effects.csv")

# 3. Filter, extract & recode columns
df = (
    df[df['description'].str.contains("fixed-poisson")]
      .assign(
         # extract the part after the last dash
         description = lambda d: d['description'].str.extract(r'([^-]+)$')[0]
           .replace({
               "all":  "Full Population",
               "highD":"Upper Vitamin D",
               "lowD": "Lower Vitamin D"
           }),
         variable = lambda d: d['variable'].replace({
             "umm":  "Humidity (mean)",
             "txab": "Temperature (max)",
             "tnab": "Temperature (min)",
             "tm":   "Temperature (avg)",
             "inst": "Sunshine (days)",
             "rr":   "Precipitations (mm)"
         })
      )
)

# 4. Compute 95% CI bounds
df['conf_low']  = df['beta'] - 1.96 * df['std']
df['conf_high'] = df['beta'] + 1.96 * df['std']


# 5. Build the plot
p = (
    ggplot(df, aes(x='beta', y='variable', color='description'))
      + geom_point(size=1.5)
      + geom_errorbarh(
          aes(xmin='conf_low', xmax='conf_high'),
          height=0.35, size=0.95
        )
      + geom_vline(xintercept=0, linetype='dashed', size=1)
      + facet_wrap('~description', ncol=1)
      + theme_minimal(base_size=14)
      + theme(
          legend_position='none',
          text=element_text(family="Times New Roman"),
          figure_size=(6, 5),
          panel_spacing=.03
        )
      + labs(x="", y="")
)

# 6. Draw it
p
```

\newpage

```{python}
#| fig-cap: DDML Estimates, Multiple Variables

import polars as pl

# 1. read & filter
df = (
    pl.read_csv("results_analysis/dml-results.csv")
      .filter(pl.col("desc") != "dml-n_ape4722z")
)

mapping_df = pl.DataFrame({
    "code": list(rename_map.keys()),
    "description": list(rename_map.values())
})

# 2) Read & transform
df = (
    pl.read_csv("results_analysis/dml-results.csv")
      # filter out that one row
      .filter(pl.col("desc") != "dml-n_ape4722z")
      # strip the prefix into a new column 'code'
      .with_columns([
          pl.col("desc")
            .str.replace("^dml-", "", literal=False)
            .alias("code")
      ])
      # left join to bring in the human labels; unmatched codes → null desc
      .join(mapping_df, on="code", how="left")
      # compute confidence intervals
      .with_columns([
          (pl.col("beta") - 1.96 * pl.col("std")).alias("conf_low"),
          (pl.col("beta") + 1.96 * pl.col("std")).alias("conf_high")
      ])
      # drop any rows where our joined-in desc is null
      .filter(pl.col("description").is_not_null())
)

p = (
    ggplot(df, aes(x='beta', y='description', color='description'))
    + geom_point(size=1.5)
    + geom_errorbarh(aes(xmin='conf_low', xmax='conf_high'),
                     height=0.2, size=0.95)
    + geom_vline(xintercept=0, linetype='dashed', size=1)
    + theme_minimal(base_size=14)
    + theme(
        legend_position='none',
        text=element_text(family="Times New Roman"),
        figure_size=(6, 3)
      )
    + labs(x="", y="")
)


p
```

\newpage 

# Conclusion

\newpage

# Bibliography 

\newpage
\setcounter{section}{0}
\renewcommand\thesection{\Alph{section}}

# Appendix 

## Note on Feature Selection

\newpage 

## Double ML Presentation

\newpage 

## Full Regression Results (Poisson / Neg. Binomial)

```{python}
#| results: asis
#| output: asis

print(build_table(
    MAIN_RESULTS[MAIN_RESULTS['description'].str.endswith(("arr24", "bv2022"))],
    include_pval=True,
    midrule_after=77,
    exclude_pattern=None
))

#print("\\begingroup\\center\\footnotesize\n" + build_table(MAIN_RESULTS, include_pval=True, midrule_after=30) + "\n\\endgroup")
```

\newpage 

## Common Support Hypothesis (DML)
```{python}
residuals = pl.read_csv('results_analysis/dml-residuals.csv')

p = (
    ggplot(df, aes(x='beta', y='variable', color='description'))
      + geom_point(size=1.5)
      + geom_errorbarh(
          aes(xmin='conf_low', xmax='conf_high'),
          height=0.35, size=0.95
        )
      + geom_vline(xintercept=0, linetype='dashed', size=1)
      + facet_wrap('~description', ncol=1)
      + theme_minimal(base_size=14)
      + theme(
          legend_position='none',
          text=element_text(family="Times New Roman"),
          figure_size=(6, 5),
          panel_spacing=.03
        )
      + labs(x="", y="")
)




# Process and merge using Polars
df_polars = (
    residuals
    .filter(pl.col('desc') != 'dml-n_ape4722z')
    .with_columns(
        pl.col('desc').str.replace('dml-', '').alias('code')
    )
    .join(mapping_df, on='code', how='left')
    .drop_nulls()
)

p = (
    ggplot(df_polars, aes(x='real_value', y='mean_prediction'))
    + geom_point(size=0.4)
    + geom_abline(intercept=0, slope=1, size = 1)
    + facet_wrap('~description', nrow=3, scales='free')
    + theme_minimal(base_size=12)
    + theme(
        legend_position='none',
        text=element_text(family="Times New Roman"),
        figure_size=(6, 6.5),
        panel_spacing=.03
    )
    + labs(x="Real Value", y="Mean Prediction")

)

p
```
